{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scale_takehome.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO8bL+lBVfGhmimG+vQs2q1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1d477329a394ba49d8d15efc0b88cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5bc1d97bd2142f5a75a2eaeff50f624",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2476ba643f9746259a6730538bb18756",
              "IPY_MODEL_80d1fed9ebbf4378ac6d1cbaba7d18c1"
            ]
          }
        },
        "e5bc1d97bd2142f5a75a2eaeff50f624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2476ba643f9746259a6730538bb18756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8548a0c3f6934f85bc7d2f439d851201",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0d6f5fefc7f4388becc5211b55d1220"
          }
        },
        "80d1fed9ebbf4378ac6d1cbaba7d18c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf76695878d34ebf849f171fcad7b28b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:12&lt;00:00,  1.12s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be1c90dc232f4684bcdfbdab9100f917"
          }
        },
        "8548a0c3f6934f85bc7d2f439d851201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0d6f5fefc7f4388becc5211b55d1220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf76695878d34ebf849f171fcad7b28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be1c90dc232f4684bcdfbdab9100f917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "920d83216bf94e26bc4a304ed2feb24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17923e1fdba34627ad1a20344557333b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be68f7ccfe0d44f6b7d2dd6d538d142a",
              "IPY_MODEL_6c04c43d63344e579494f4c58229c22c"
            ]
          }
        },
        "17923e1fdba34627ad1a20344557333b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be68f7ccfe0d44f6b7d2dd6d538d142a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d469291f454424c9addca770e044198",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_077f7396d81c422b9af42b98bfece70a"
          }
        },
        "6c04c43d63344e579494f4c58229c22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8bf12700ec1941239cebf6806fc80ba8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 3.18kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfad562e12af40f7bcb5d0b9b2f3e3fc"
          }
        },
        "5d469291f454424c9addca770e044198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "077f7396d81c422b9af42b98bfece70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bf12700ec1941239cebf6806fc80ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfad562e12af40f7bcb5d0b9b2f3e3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d64afba818744199afa06ddeedec2f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f1db31cc39448afb5b084d7f894197e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1e000ecc5054fafb88bcd56eb2526e8",
              "IPY_MODEL_eb37884b3dce41429c09832b296cde94"
            ]
          }
        },
        "8f1db31cc39448afb5b084d7f894197e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1e000ecc5054fafb88bcd56eb2526e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c882a154ddf494db32394f316fcbbf2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242065649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242065649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_087c2ae139a34e4588bed7db33824512"
          }
        },
        "eb37884b3dce41429c09832b296cde94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06cc4834324c4ab29808c587e12589c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:07&lt;00:00, 31.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a646febb8a714a8a96c7401877c7c287"
          }
        },
        "3c882a154ddf494db32394f316fcbbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "087c2ae139a34e4588bed7db33824512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06cc4834324c4ab29808c587e12589c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a646febb8a714a8a96c7401877c7c287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murdo25/DeepLearningZoo/blob/master/t5_for_poly_expansion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGT_DBjMi2aL",
        "outputId": "9b693809-7706-46ee-93fd-3466b8ff0805"
      },
      "source": [
        "!pip install nlp\r\n",
        "!pip install tqd\r\n",
        "!pip install transformers\r\n",
        "!pip install sentencepiece\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/e3/bcdc59f3434b224040c1047769c47b82705feca2b89ebbc28311e3764782/nlp-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\r\u001b[K     |▏                               | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 26.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 31.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 22.4MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 16.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 15.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81kB 13.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92kB 14.0MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 12.8MB/s eta 0:00:01\r\u001b[K     |███                             | 153kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194kB 12.8MB/s eta 0:00:01\r\u001b[K     |████                            | 204kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 215kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 225kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 235kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 256kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 266kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 276kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 286kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 296kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 307kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 317kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 327kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 337kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 348kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 358kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 368kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 378kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 389kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 399kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 409kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 419kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 430kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 440kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 450kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 460kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 471kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 481kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 491kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 501kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 512kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 522kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 532kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 542kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 552kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 563kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 573kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 583kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 593kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 604kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 614kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 624kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 634kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 645kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 655kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 665kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 675kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 686kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 696kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 706kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 716kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 727kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 737kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 747kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 757kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 768kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 778kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 788kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 798kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 808kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 819kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 829kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 839kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 849kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 860kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 870kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 880kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 890kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 901kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 911kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 921kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 931kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 942kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 952kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 962kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 972kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 983kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 993kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.8)\n",
            "Collecting pyarrow>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 352kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n",
            "Installing collected packages: xxhash, pyarrow, nlp\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed nlp-0.4.0 pyarrow-2.0.0 xxhash-2.0.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tqd (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tqd\u001b[0m\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 60.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 61.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=75d0f6210a622b8fd19db814ef71682eab4949e4199d5c08c876c43a35bf3b50\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 13.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ERwJ2HiC28"
      },
      "source": [
        "from nlp import Dataset\r\n",
        "\r\n",
        "def clean(data_path):\r\n",
        "    open_file = open(data_path, 'r').readlines()\r\n",
        "\r\n",
        "    lines = []\r\n",
        "    # Strips the newline character \r\n",
        "    for line in open_file: \r\n",
        "        line = line.strip()\r\n",
        "        lines.append(line)\r\n",
        "    return lines\r\n",
        "\r\n",
        "def build_dataset(data_file):\r\n",
        "\r\n",
        "    lines = clean(data_file)\r\n",
        "\r\n",
        "    datapoints = {}\r\n",
        "    datapoints['input_text']= []\r\n",
        "    datapoints['target_text']= []\r\n",
        "\r\n",
        "    for line in lines:\r\n",
        "\r\n",
        "        # Split the first half  and second half\r\n",
        "        input_text, target_text = line.split('=')\r\n",
        "\r\n",
        "        # Construct positive example \r\n",
        "        datapoints['input_text'].append(input_text)\r\n",
        "        datapoints['target_text'].append(target_text)\r\n",
        "\r\n",
        "    assert len(datapoints['target_text']) == len(datapoints['input_text']), \"incorrect data distribution\"\r\n",
        "\r\n",
        "    # from nlp import Dataset\r\n",
        "    return Dataset.from_dict(datapoints)\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_30qDIdtHGD"
      },
      "source": [
        "import tqdm\r\n",
        "import torch\r\n",
        "import nlp\r\n",
        "from transformers import T5Tokenizer\r\n",
        "import json\r\n",
        "import dataclasses\r\n",
        "import logging\r\n",
        "import os\r\n",
        "import sys\r\n",
        "from dataclasses import dataclass, field\r\n",
        "from typing import Dict, List, Optional\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "d1d477329a394ba49d8d15efc0b88cd1",
            "e5bc1d97bd2142f5a75a2eaeff50f624",
            "2476ba643f9746259a6730538bb18756",
            "80d1fed9ebbf4378ac6d1cbaba7d18c1",
            "8548a0c3f6934f85bc7d2f439d851201",
            "c0d6f5fefc7f4388becc5211b55d1220",
            "cf76695878d34ebf849f171fcad7b28b",
            "be1c90dc232f4684bcdfbdab9100f917"
          ]
        },
        "id": "FVCEweb4qQmN",
        "outputId": "7b77f370-75d4-46af-a8ba-1bf5649ac5e1"
      },
      "source": [
        "# tokenize the examples\r\n",
        "def convert_to_features(example_batch):\r\n",
        "    input_encodings  = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=128)\r\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=129)\r\n",
        "\r\n",
        "    encodings = {\r\n",
        "        'input_ids': input_encodings['input_ids'], \r\n",
        "        'attention_mask': input_encodings['attention_mask'],\r\n",
        "        'target_ids': target_encodings['input_ids'],\r\n",
        "        'target_attention_mask': target_encodings['attention_mask']\r\n",
        "    }\r\n",
        "\r\n",
        "    return encodings\r\n",
        "\r\n",
        "\r\n",
        "# train_dataset = build_dataset('half_train_set.txt')\r\n",
        "valid_dataset = build_dataset('validation_set_10k.txt')\r\n",
        "\r\n",
        "\r\n",
        "# map convert_to_features batch wise\r\n",
        "# train_dataset = train_dataset.map(convert_to_features, batched=True)\r\n",
        "valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\r\n",
        "\r\n",
        "# set the tensor type and the columns which the dataset should return\r\n",
        "columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\r\n",
        "# train_dataset.set_format(type='torch', columns=columns)\r\n",
        "valid_dataset.set_format(type='torch', columns=columns)\r\n",
        "\r\n",
        "# cach the dataset, so we can load it directly for training\r\n",
        "\r\n",
        "# torch.save(train_dataset, 'train_data.pt')\r\n",
        "torch.save(valid_dataset, 'valid_data.pt')\r\n",
        "\r\n",
        "\r\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, EvalPrediction\r\n",
        "from transformers import (\r\n",
        "    HfArgumentParser,\r\n",
        "    DataCollator,\r\n",
        "    Trainer,\r\n",
        "    TrainingArguments,\r\n",
        "    set_seed,\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "\r\n",
        "from data_classes import T2TDataCollator, ModelArguments, DataTrainingArguments\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1d477329a394ba49d8d15efc0b88cd1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "920d83216bf94e26bc4a304ed2feb24d",
            "17923e1fdba34627ad1a20344557333b",
            "be68f7ccfe0d44f6b7d2dd6d538d142a",
            "6c04c43d63344e579494f4c58229c22c",
            "5d469291f454424c9addca770e044198",
            "077f7396d81c422b9af42b98bfece70a",
            "8bf12700ec1941239cebf6806fc80ba8",
            "dfad562e12af40f7bcb5d0b9b2f3e3fc",
            "d64afba818744199afa06ddeedec2f6e",
            "8f1db31cc39448afb5b084d7f894197e",
            "a1e000ecc5054fafb88bcd56eb2526e8",
            "eb37884b3dce41429c09832b296cde94",
            "3c882a154ddf494db32394f316fcbbf2",
            "087c2ae139a34e4588bed7db33824512",
            "06cc4834324c4ab29808c587e12589c0",
            "a646febb8a714a8a96c7401877c7c287"
          ]
        },
        "id": "XdpyzaYctOpl",
        "outputId": "07457602-5ed3-4504-d6ac-a95705748b94"
      },
      "source": [
        "def main():\r\n",
        "    # See all possible arguments in src/transformers/training_args.py\r\n",
        "    # or by passing the --help flag to this script.\r\n",
        "    # We now keep distinct sets of args, for a cleaner separation of concerns.\r\n",
        "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\r\n",
        "\r\n",
        "    # we will load the arguments from a json file, \r\n",
        "    #make sure you save the arguments in at ./args.json\r\n",
        "    model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath('args.json'))\r\n",
        "\r\n",
        "    if (\r\n",
        "        os.path.exists(training_args.output_dir)\r\n",
        "        and os.listdir(training_args.output_dir)\r\n",
        "        and training_args.do_train\r\n",
        "        and not training_args.overwrite_output_dir\r\n",
        "    ):\r\n",
        "        raise ValueError(\r\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\r\n",
        "        )\r\n",
        "\r\n",
        "    # Setup logging\r\n",
        "    logging.basicConfig(\r\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\r\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\r\n",
        "        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\r\n",
        "    )\r\n",
        "    logger.warning(\r\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\r\n",
        "        training_args.local_rank,\r\n",
        "        training_args.device,\r\n",
        "        training_args.n_gpu,\r\n",
        "        bool(training_args.local_rank != -1),\r\n",
        "        training_args.fp16,\r\n",
        "    )\r\n",
        "    logger.info(\"Training/evaluation parameters %s\", training_args)\r\n",
        "\r\n",
        "    # Set seed\r\n",
        "    set_seed(training_args.seed)\r\n",
        "\r\n",
        "    # Load pretrained model and tokenizer\r\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\r\n",
        "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\r\n",
        "        cache_dir=model_args.cache_dir,\r\n",
        "    )\r\n",
        "\r\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\r\n",
        "        model_args.model_name_or_path,\r\n",
        "        cache_dir=model_args.cache_dir,\r\n",
        "    )\r\n",
        "\r\n",
        "    # Get datasets\r\n",
        "    train_dataset  = torch.load(data_args.train_file_path)\r\n",
        "    valid_dataset = torch.load(data_args.valid_file_path)\r\n",
        "\r\n",
        "    # Initialize our Trainer\r\n",
        "    trainer = Trainer(\r\n",
        "        model=model,\r\n",
        "        args=training_args,\r\n",
        "        train_dataset=train_dataset,\r\n",
        "        eval_dataset=valid_dataset,\r\n",
        "        data_collator=T2TDataCollator(),\r\n",
        "    )\r\n",
        "    \r\n",
        "    # Training\r\n",
        "    if training_args.do_train:\r\n",
        "        loss = trainer.train(\r\n",
        "            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\r\n",
        "        )\r\n",
        "        print(\"loss: \", loss)\r\n",
        "        trainer.save_model()\r\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\r\n",
        "\r\n",
        "    # Evaluation\r\n",
        "    results = {}\r\n",
        "    if training_args.do_eval and training_args.local_rank in [-1, 0]:\r\n",
        "        logger.info(\"*** Evaluate ***\")\r\n",
        "\r\n",
        "        eval_output = trainer.evaluate()\r\n",
        "\r\n",
        "        output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\r\n",
        "        with open(output_eval_file, \"w\") as writer:\r\n",
        "            logger.info(\"***** Eval results *****\")\r\n",
        "            for key in sorted(eval_output.keys()):\r\n",
        "                logger.info(\"  %s = %s\", key, str(eval_output[key]))\r\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(eval_output[key])))\r\n",
        "    \r\n",
        "        results.update(eval_output)\r\n",
        "    \r\n",
        "    return results\r\n",
        "\r\n",
        "args_dict = {\r\n",
        "  \"num_cores\": 8,\r\n",
        "  'training_script': 'train_t5_squad.py',\r\n",
        "  \"model_name_or_path\": 't5-small',\r\n",
        "  \"max_len\": 512 ,\r\n",
        "  \"target_max_len\": 16,\r\n",
        "  \"output_dir\": './models/gpu',\r\n",
        "  \"overwrite_output_dir\": True,\r\n",
        "  \"per_gpu_train_batch_size\": 8,\r\n",
        "  \"per_gpu_eval_batch_size\": 8,\r\n",
        "  \"gradient_accumulation_steps\": 4,\r\n",
        "  \"learning_rate\": 1e-4,\r\n",
        "  \"tpu_num_cores\": 8,\r\n",
        "  \"do_train\": True,\r\n",
        "  \"num_train_epochs\": 32\r\n",
        "}\r\n",
        "\r\n",
        "with open('args.json', 'w') as f:\r\n",
        "  json.dump(args_dict, f)\r\n",
        "\r\n",
        "\"\"\"Start training!\"\"\"\r\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/14/2021 06:39:05 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "01/14/2021 06:39:05 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=./models/gpu, overwrite_output_dir=True, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=4, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=32, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Jan14_06-39-04_575ba0fc85ca, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=8, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=./models/gpu, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, _n_gpu=1)\n",
            "01/14/2021 06:39:05 - INFO - filelock -   Lock 140612341154928 acquired on /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "920d83216bf94e26bc4a304ed2feb24d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1197.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/14/2021 06:39:05 - INFO - filelock -   Lock 140612341154928 released on /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "01/14/2021 06:39:06 - INFO - filelock -   Lock 140612340275352 acquired on /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d64afba818744199afa06ddeedec2f6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242065649.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/14/2021 06:39:08 - INFO - filelock -   Lock 140612340275352 released on /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
            "/usr/local/lib/python3.6/dist-packages/nlp/utils/py_utils.py:191: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return function(data_struct)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='83501' max='500000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 83501/500000 11:11:00 < 55:47:01, 2.07 it/s, Epoch 5.34/32]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.377100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.887700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.815500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.761800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.711500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.671000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.640300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.605300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.584900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.559100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.541100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.518600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.497700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.485300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.467500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.447400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.435900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.421500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.406400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.382200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.376500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.366300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.347900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.334500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.331800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.324700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.315900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.309500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.300600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.293800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.290200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.284400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.274100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.272500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.267200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.261000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>0.257200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.250500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.249800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.243100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.237700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>0.233500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.229700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>0.228800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.224900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>0.223800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.220300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>0.215000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.213700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>0.211200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.209300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.207000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>0.205100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.204400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>0.199800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.201200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31500</td>\n",
              "      <td>0.196600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.194000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32500</td>\n",
              "      <td>0.195300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.190100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33500</td>\n",
              "      <td>0.188700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.189400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34500</td>\n",
              "      <td>0.188000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.185700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35500</td>\n",
              "      <td>0.185400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.184800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36500</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>0.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37500</td>\n",
              "      <td>0.179500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>0.176500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38500</td>\n",
              "      <td>0.177200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>0.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39500</td>\n",
              "      <td>0.175200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.174900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40500</td>\n",
              "      <td>0.171800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>0.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41500</td>\n",
              "      <td>0.171100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>0.170200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42500</td>\n",
              "      <td>0.168900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>0.169800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43500</td>\n",
              "      <td>0.166100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>0.166500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44500</td>\n",
              "      <td>0.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.164100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45500</td>\n",
              "      <td>0.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>0.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46500</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47000</td>\n",
              "      <td>0.162700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47500</td>\n",
              "      <td>0.157900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48000</td>\n",
              "      <td>0.159200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48500</td>\n",
              "      <td>0.159800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49000</td>\n",
              "      <td>0.157200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49500</td>\n",
              "      <td>0.157100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>0.155400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50500</td>\n",
              "      <td>0.154400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51000</td>\n",
              "      <td>0.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51500</td>\n",
              "      <td>0.151800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52000</td>\n",
              "      <td>0.152100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52500</td>\n",
              "      <td>0.151700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53000</td>\n",
              "      <td>0.151500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53500</td>\n",
              "      <td>0.150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54000</td>\n",
              "      <td>0.149800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54500</td>\n",
              "      <td>0.150300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55000</td>\n",
              "      <td>0.148400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55500</td>\n",
              "      <td>0.146300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56000</td>\n",
              "      <td>0.148500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56500</td>\n",
              "      <td>0.146100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57000</td>\n",
              "      <td>0.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57500</td>\n",
              "      <td>0.144400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58000</td>\n",
              "      <td>0.144700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58500</td>\n",
              "      <td>0.144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59000</td>\n",
              "      <td>0.142100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59500</td>\n",
              "      <td>0.144100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>0.142400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60500</td>\n",
              "      <td>0.138900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61000</td>\n",
              "      <td>0.139500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61500</td>\n",
              "      <td>0.141100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62000</td>\n",
              "      <td>0.137900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62500</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63000</td>\n",
              "      <td>0.138000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63500</td>\n",
              "      <td>0.134900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64000</td>\n",
              "      <td>0.137000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64500</td>\n",
              "      <td>0.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65000</td>\n",
              "      <td>0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65500</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66000</td>\n",
              "      <td>0.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66500</td>\n",
              "      <td>0.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67000</td>\n",
              "      <td>0.131800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67500</td>\n",
              "      <td>0.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68000</td>\n",
              "      <td>0.131300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68500</td>\n",
              "      <td>0.131900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69000</td>\n",
              "      <td>0.131200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69500</td>\n",
              "      <td>0.129800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>0.129600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70500</td>\n",
              "      <td>0.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71000</td>\n",
              "      <td>0.127300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71500</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72000</td>\n",
              "      <td>0.125800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72500</td>\n",
              "      <td>0.125700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73000</td>\n",
              "      <td>0.127100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73500</td>\n",
              "      <td>0.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74000</td>\n",
              "      <td>0.124800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74500</td>\n",
              "      <td>0.124400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75000</td>\n",
              "      <td>0.123000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75500</td>\n",
              "      <td>0.125700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76000</td>\n",
              "      <td>0.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76500</td>\n",
              "      <td>0.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77000</td>\n",
              "      <td>0.123700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77500</td>\n",
              "      <td>0.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78000</td>\n",
              "      <td>0.120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78500</td>\n",
              "      <td>0.118400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79000</td>\n",
              "      <td>0.117900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79500</td>\n",
              "      <td>0.118700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80000</td>\n",
              "      <td>0.119100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80500</td>\n",
              "      <td>0.117400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81000</td>\n",
              "      <td>0.117100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81500</td>\n",
              "      <td>0.117100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82000</td>\n",
              "      <td>0.117200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82500</td>\n",
              "      <td>0.117700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83000</td>\n",
              "      <td>0.116400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-01f0a003776e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\"\"\"Start training!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-01f0a003776e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         loss = trainer.train(\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    927\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_epoch_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_training_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_flos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model weights saved in {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 176280704 vs 176280592"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqpPzCJfBeWM",
        "outputId": "073532e8-82f4-4150-e42d-24275cd9b172"
      },
      "source": [
        "# F1: https://en.wikipedia.org/wiki/F-score\r\n",
        "\r\n",
        "## SQuAD evaluation script. Modifed slightly for this notebook\r\n",
        "from data_classes import ModelArguments\r\n",
        "from transformers import HfArgumentParser\r\n",
        "parser = HfArgumentParser(ModelArguments)\r\n",
        "\r\n",
        "from collections import Counter\r\n",
        "import string\r\n",
        "import re\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import nlp\r\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, set_seed \r\n",
        "from tqdm.auto import tqdm\r\n",
        "from os import listdir\r\n",
        "set_seed(42)\r\n",
        "\r\n",
        "\r\n",
        "def normalize_answer(s):\r\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\r\n",
        "    def remove_articles(text):\r\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\r\n",
        "\r\n",
        "    def white_space_fix(text):\r\n",
        "        return ' '.join(text.split())\r\n",
        "\r\n",
        "    def remove_punc(text):\r\n",
        "        exclude = set(string.punctuation)\r\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\r\n",
        "\r\n",
        "    def lower(text):\r\n",
        "        return text.lower()\r\n",
        "\r\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\r\n",
        "\r\n",
        "\r\n",
        "def f1_score(prediction, ground_truth):\r\n",
        "    prediction_tokens = normalize_answer(prediction).split()\r\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\r\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\r\n",
        "    num_same = sum(common.values())\r\n",
        "    if num_same == 0:\r\n",
        "        return 0\r\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\r\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\r\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\r\n",
        "    return f1\r\n",
        "\r\n",
        "\r\n",
        "def exact_match_score(prediction, ground_truth):\r\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\r\n",
        "\r\n",
        "\r\n",
        "def evaluate(gold_answers, predictions):\r\n",
        "    f1 = exact_match = total = 0\r\n",
        "\r\n",
        "    for ground_truth, prediction in zip(gold_answers, predictions):\r\n",
        "      total += 1\r\n",
        "      exact_match += exact_match_score(prediction, ground_truth)\r\n",
        "      f1 += f1_score(prediction, ground_truth)\r\n",
        "    \r\n",
        "    exact_match = 100.0 * exact_match / total\r\n",
        "    f1 = 100.0 * f1 / total\r\n",
        "\r\n",
        "    return {'exact_match': exact_match, 'f1': f1}\r\n",
        "\r\n",
        "def clean(result):\r\n",
        "    result = result.replace(\"<pad>\",\"\")\r\n",
        "    result = result.replace(\"</s>\", \"\")\r\n",
        "    result = result.strip()\r\n",
        "    result = result.lower()\r\n",
        "    return result\r\n",
        "\r\n",
        "# model_path = \"models/gpu/checkpoint-11000\"\r\n",
        "model_path = \"models/gpu/\"\r\n",
        "checkpoints = \"models/gpu/\"\r\n",
        "\r\n",
        "print(listdir(checkpoints))\r\n",
        "\r\n",
        "for checkpoint in listdir(checkpoints):\r\n",
        "    # print(\"checkpoint:\", checkpoint)\r\n",
        "    if(checkpoint.split(\"-\")[0] != \"checkpoint\"):\r\n",
        "        continue\r\n",
        "    # if(checkpoint.split(\"-\")[1] != \"83000\"):\r\n",
        "    #     continue\r\n",
        "\r\n",
        "    print(checkpoint.split(\"-\")[1])\r\n",
        "\r\n",
        "    print(\"checkpoint:\", checkpoint)\r\n",
        "\r\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_path + checkpoint).to('cuda')\r\n",
        "\r\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-small')\r\n",
        "\r\n",
        "    valid_dataset = torch.load('valid_data.pt')\r\n",
        "    dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=256)\r\n",
        "\r\n",
        "    answers = []\r\n",
        "    for batch in dataloader:\r\n",
        "      outs = model.generate(input_ids=batch['input_ids'].to('cuda'), \r\n",
        "                            attention_mask=batch['attention_mask'].to('cuda'),\r\n",
        "                            max_length=16,\r\n",
        "                            early_stopping=True)\r\n",
        "      outs = [tokenizer.decode(ids) for ids in outs]\r\n",
        "      answers.extend(outs)\r\n",
        "\r\n",
        "    predictions = []\r\n",
        "    references = []\r\n",
        "    for ref, pred in zip(valid_dataset, answers):\r\n",
        "      predictions.append(clean(pred))\r\n",
        "      references.append(clean(tokenizer.decode(ref['target_ids'])))\r\n",
        "\r\n",
        "    print(checkpoint, evaluate(references, predictions))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.ipynb_checkpoints', 'checkpoint-20000']\n",
            "20000\n",
            "checkpoint: checkpoint-20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nlp/utils/py_utils.py:191: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return function(data_struct)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "checkpoint-20000 {'exact_match': 85.56144385561444, 'f1': 85.56144385561444}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHtCOZvtk2Ms",
        "outputId": "a355de34-1327-4ac9-e08d-231393e72d55"
      },
      "source": [
        "!zip -r checkpoint-83000.zip models/gpu/checkpoint-83000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: models/gpu/checkpoint-83000/ (stored 0%)\n",
            "  adding: models/gpu/checkpoint-83000/config.json (deflated 63%)\n",
            "  adding: models/gpu/checkpoint-83000/trainer_state.json (deflated 88%)\n",
            "  adding: models/gpu/checkpoint-83000/pytorch_model.bin (deflated 9%)\n",
            "  adding: models/gpu/checkpoint-83000/training_args.bin (deflated 46%)\n",
            "  adding: models/gpu/checkpoint-83000/optimizer.pt (deflated 7%)\n",
            "  adding: models/gpu/checkpoint-83000/scheduler.pt (deflated 49%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxo2AUzDpAjy"
      },
      "source": [
        "!rm checkpoint-83000.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZgypfQvqIpW",
        "outputId": "da7b9228-4d42-4b26-afcf-016c50d317b0"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpyxajMJq3zn"
      },
      "source": [
        "!cp checkpoint-83000.zip gdrive/MyDrive/colab/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9-MqOm8rRqm",
        "outputId": "91256da2-a59d-4015-a961-4eb91ad6bae1"
      },
      "source": [
        "!ls -lt gdrive/MyDrive/colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'gdrive/MyDrive/colab': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}